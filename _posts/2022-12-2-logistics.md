---
layout:     post
title:      斯坦福21秋：实用机器学习——学习笔记1（1.1课程介绍-1.4数据标注）
subtitle:   最好的机器学习课程之一
date:       2022-12-2
author:     Chengrui
header-img: img/machine_learning.jpg
catalog: true
tags:
    - 实用机器学习
    - 学习笔记
---

# 斯坦福21秋：实用机器学习——学习笔记1

### 讲在前面

制作这个笔记博客是受知名的科学家，同时也是这门课的主讲人之一：李沐教授的启发。李沐教授在每天处理各种各样的教学以及科研事务的同时，仍然心系国内的学子，将这门课用中文重新讲授了一遍并发表在b站上。作者被这种共享和开源的精神深深打动，于是决定也做一些什么来为整个社区的开源环境做出一些贡献。俗话说：前人栽树，后人乘凉。在很多领域还亟待发掘的机器学习这一学科下，希望能够有越来越多的人互帮互助，为学科做出更大的贡献。

同时，对费曼学习法深以为然的我也觉得将自己所学内容进行整理以及对输入内容进行再生产是巩固知识的良好方法，于是这篇博客应运而生。



李沐教授的b站主页：[https://space.bilibili.com/1567748478](https://space.bilibili.com/1567748478)

b站的中文版课程资源：[https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358496](https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358496) 

课程的官方网站： [https://c.d2l.ai/stanford-cs329p/index.html](https://c.d2l.ai/stanford-cs329p/index.html)



### 1.1 课程简介

##### 课程目标

- 讨论一些在机器学习中重要但是常被忽略的问题：	
  - **数据**：收集数据、处理数据，数据特征，数据集偏移等
  - **模型训练**：模型的选择、调试，迁移学习，多模态，知识蒸馏，可扩展性
  - **部署**：效率，公平性，以及服务

- 对于一些问题进行实现（Python）
- 机器学习研究的实践（Project）
- 不会讨论基础的统计、代数、Python语法等知识，需要先修课程的支撑

##### 机器学习在工业界的应用

- 十几年前机器学习主要由一些大型科技公司使用

- 现在大量公司使用机器学习驱动最重要的应用设计（Mckinsey：近一半的公司在使用机器学习之后有了6%以上的收入增加）

  ![image-20221202201947892](https://i.imgur.com/MrzoQgy.png)

  - 热门领域：自动驾驶，智能制造
  - 新冠疫情加速了这个过程

- 制造业：预测设备的磨损状况和可能的维修需求，品控管理
- 零售业：商品推荐，需求预测，AI客服
- 医疗行业：疾病检测（CT分析），实时健康状况监测
- 金融业：诈骗监测，贷款申请处理
- 汽车工业：维护预测，无人驾驶

##### 机器学习的流程

1. 问题形成（如何将应用需求转化成为机器学习的问题）
2. 数据收集&数据处理
3. 模型训练&模型调试
4. 将模型部署到线上
5. 监测模型的性能（反馈至第2步，完成迭代的过程）

##### 样例：房价预测

在美国，买房有竞价的过程，预测最终winning buyer的出价：

1. 问题：预测房价（回归问题，预测实数的值）
2. 收集数据（成交记录）
3. 训练模型（从简单模型开始（如线性回归），测试数据的好坏）
4. 部署模型（指导用户进行交易）
5. 监测与反馈

##### 挑战与困难

1. 问题形成：（关注最大化利润的问题，而不是适合机器学习的问题，有些问题较难）
2. 数据：***高质量***的数据较为稀缺，数据挖掘带来的隐私问题
3. 模型训练：模型越来越复杂，越来越昂贵(The Economist：训练AI系统所带来的计算资源消耗呈指数级增长)![Economist_Survey](https://i.imgur.com/9k1SzD4.png)
4. 模型部署：大计算量的模型不适合数据的实时反馈
5. 性能监测：数据偏移（节假日用户行为出现大的变化），公平性的问题（数据带有人群的偏好性）

##### 角色

- 领域专家，懂得产品目标，应用场景，如何让模型使效益最大化
- 数据科学家：负责数据挖掘，训练模型以及部署模型
- 机器学习专家：定制化机器学习模型，使其更加适合应用场景
- 软件开发工程师（SDE）：开发，维护代码，更新模型和数据

##### 职业规划与个人能力提升

从领域专家和软件开发工程师做起，在不断的实践中学习如何处理数据与训练模型,从而成为一名数据科学家（人才急缺），最后成为机器学习的专家

数据科学家的时间分配（Anaconda Survey，2022）

![image-20221202205923835](https://i.imgur.com/EhqdyDY.png)

##### 课程内容

- 数据：
  - 数据的处理和收集
  - 数据偏移，概念变化
  - 在IID之外的数据（非独立同分布）

- 训练：
  - 模型验证，模型调试，模型的融合
  - 迁移学习
  - 多模态

- 部署
  - 模型的蒸馏

- 监视
  - 可解释性
  - 公平性



### 1.2 数据获取

假设我们完成了1.1中将实际问题转化为机器学习问题的这一步：

1. 拥有足够多的数据——课程之后内容
2. 没有足够的多的数据，但是可以找到足够多的可用数据集——**数据的探索和融合**
3. 前两者皆无，但是有可靠的生成数据的方法——**数据的生成** 

##### 可用数据的发现

- 寻找已有的数据集，e.g 利用已有数据集验证模型的超参数（需要小数据集）；验证大型神经网络（需要大数据集）
- 收集数据，e.g 在汽车上安装各种传感器为无人驾驶AI采集数据（需要考虑到应用的方方面面）

##### 常见的可用数据集

- **MNIST**: US Census Bureau 雇员的手写数字
- **ImageNet**：来自搜索引擎的百万量级的图片
- **AudioSet**：YouTube上的声音片段
- **Kinetics**：YouTube上人类活动的视频片段
- **KITTI**：用于无人驾驶的交通情景的数据集
- **Amazon Review**：Amazon的购物评论
- **SQuAD**：来自维基百科的 问题-答案 组
- **LibriSpeech**：1000个小时的有声读物片段

用于机器学习研究的数据集：[https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research)

来源大致可分为两种

1. 爬虫
2. 采集

这也是实际上工业中常用的两种方法

##### 如何寻找合适的数据集

- [https://paperswithcode.com/datasets](https://paperswithcode.com/datasets) 学术论文所用的数据集
- [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)：Kaggle竞赛使用的数据集
- [https://datasetsearch.research.google.com](https://datasetsearch.research.google.com)：Google的数据集搜索服务
- 各种机器学习toolkit自带的数据集：tensorflow等
- [https://registry.opendata.aws](https://registry.opendata.aws)：各种大型原始数据
- ”数据湖“（各大机构自己内部的数据）

##### 各种数据集的比较

|                | 优点                   | 缺点                                                         |
| -------------- | ---------------------- | ------------------------------------------------------------ |
| **学术数据集** | 干净，难度适中         | 选择有限，简化过度，尺度通常较小（常常用来测试算法而不是应用） |
| **竞赛数据集** | 更加贴近实际应用，干净 | 同样有所简化，只有热门方向的数据好找（无人车，电商）         |
| **原始数据**   | 极大的灵活性           | 需要大量时间和精力处理数据                                   |

- 工业实际应用中，原始数据更加常见
- 工作流程需要成熟的团队：法律问题，隐私问题，工作流程管理...

##### 数据融合

数据融合指的是将不同源的数据融合到同一个数据集中(同一件事物的不同特征可能存储在不同的源中)

常见的数据融合：Table类型数据的 JOIN操作（图片来自[https://www.w3schools.com/sql/sql_join.asp](https://www.w3schools.com/sql/sql_join.asp)）

![SQL Joins](https://i.imgur.com/wWvq3RO.png)

关键问题：ID识别，空缺的数据，重复的列，重复列的数值冲突（错误的数据，不同精度的数据）

##### 数据生成

- 使用GAN（无监督的方法）生成数据  [https://thispersondoesnotexist.com](https://thispersondoesnotexist.com))
- 数据增强（对已有的数据加入一些噪音）文本的反复翻译（英-法-英：I have no time---I don't have time）

##### 小结

1. 找到合适的数据有时很难
2. 原始数据 VS 学术数据
3. 不同源的数据整合
4. 数据增强是一种常见的做法
5. 人工合成的数据逐渐占据主流（成本低、可控）

### 1.3 网页数据抓取

网页数据抓取的目标是从网上获取数据

特点：噪音多，标号弱，数据量大，但可能有大量无用的信息

例子：比较商品价格（时间轴，商家轴），大量机器学习数据集也来自数据抓取（Kinetic，ImageNet）

网页爬虫 VS 数据抓取

- 爬虫：索引所有互联网上的页面
- 数据抓取：对特定的网站中的一些特定的数据感兴趣

##### 数据抓取的常用工具

- “curl”经常无法使用：网站管理员在使用反爬工具

- 使用headless browser ：没有GUI的浏览器，使用如下代码(视频中沐神给的代码在我这里没有成功，贴上我成功的代码,同时，zillow网站现在有了反爬，视频里的例子现在无法运行，这里爬取python官网的数据)

  ```python
  from selenium import webdriver
  import time
  options = webdriver.ChromeOptions()
  options.headless =  True
  
  ##使用无GUI的浏览器
  
  chrome = webdriver.Chrome('/Users/chengruisun/Documents/Work/2021Fall_Practical_ML/chromedriver', options = options)
  
  ##下载”chromedriver“ executable文件把这里的路径替换为你chromedriver的位置
  
  f = open("index.html", 'wb')
  chrome.get('https://python.org')
  time.sleep(2)
  
  ##等待确保网页响应
  
  f.write(chrome.page_source.encode('gbk', 'ignore'))
  
  ##开始写入
  
  print('写入成功')
  f.close()
  ```

  还需要大量的IP防止IP检测：所有IPv4中，AWS拥有1.75%

##### 数据抓取实例

在zillow上抓取Stanford附近房子的销售记录：

```python
from bs4 import BeautifulSoup
page = BeautifulSoup(open(html_path, 'r'))

##用BeautifulSoup解析磁盘上的html文件

links = [a['href'] for a in page.find_all('a', 'list-card-link')]

##找出html中所有的link元素（url）

ids = [l.split('/')[-2].split('_')[0] for l in links]

##正则表达式匹配房子的id
```

##### 成本

- 使用AWS EC2 t3.small （2GB内存，2个CPU，每小时两美分）
  - 2GB对于浏览器来说是必要的，CPU和带宽一般不关键
  - 可以在AWS竞价来省钱

- 爬一百万个房子的价格：16.6美元
  - 每个网页需要3秒爬取
  - 用100台机器需要8.3个小时
  - 额外开销包括数据储存，换IP需要重启

##### 爬取图片

- 获取图片的URL

```python
p = r'https:\\/\\/photos.zillowstatic.com\\/fp\\/([\d\w\-\_]+).jpg'
ids = [a.split('-')[0] for a in re.findall(p, html)]
urls = [f'https://photos.zillowstatic.com/fp/{id}-uncropped_scaled_within_1536_1152.jpg' for id in ids]
```

- 最大的成本在于存储

##### 法律上的考虑

- 网页抓取本身不是非法的
- 但是仍然要注意
  - 不要爬取带有敏感信息的数据
  - 不要爬取隐私数据
  - 不要爬取有版权的数据
  - 遵守网页的服务条款

- 如果你在以商业目的爬取数据，在行动之前咨询律师

##### 小结

- 在网站本身不提供数据链接的时候，数据抓取是常用的获取数据的方法
- 如果使用公共云平台会有更低的成本
- 记得使用审查工具来定位html中的信息
- 最后：爬取数据一定要慎重

### 1.4 数据标注

假设已经有了足够的数据：

1. 考虑是否需要提升标注、模型和数据的质量——（后续内容）
2. 假设有足够的标注——半监督学习
3. 假设没有足够的的标注，但是有足够的预算——众包人工标注
4. 假设以上两者皆无——弱监督学习

##### 半监督学习（Semi-Supervised Learning，SSL）

- 主要适用于一小部分数据有标注，但更多的数据没有
- 为了使用这些未标注的数据，做出以下假设：
  - **连续性假设**：如果一个样本和另外一个样本的特征相似，那么这两个样本很可能有相同的标注
  - **聚类假设**：如果数据内部有着聚类的结构，那么可以假设同类数据内部有着相同的标注
  - **流形假设**：数据本身可能在比输入更低维的空间流形上分布

##### 自学习（Self-training）

- 自学习是一种半监督学习常用的方法
  - 先在一小部分有标注的数据上训练一个模型
  - 利用模型预测未标注的数据生成伪标注的数据
  - 将伪标注的数据中置信度高的（eg.三分类问题中有一类概率很高，称为高置信，如果三类的概率相近，称为低置信）输入模型重新训练，并不断迭代

- 可以利用相对昂贵的模型增加计算复杂度提升模型精确度：大型神经网络等

##### 众包人工标注（Crowdsourcing）

- ImageNet数据集通过Amazon Mechanical Turk标注了上百万的图像数据
- ![image-20221205214133683](https://tva1.sinaimg.cn/large/008vxvgGgy1h8u250blnmj30qu0dkgmc.jpg)

- 人工标注的挑战：
  - 分类者的学历不高，所以需要设计相对简单的任务和清晰的指示
  - 成本问题
  - 控制标注的质量

##### 主动学习：减少人工标注的任务量（Active Learning）

- Uncertainty Sampling：选择那些置信度低的样本（最高的可能性接近随机($\frac{1}{n}$)）交给人工标注
- 和自主学习相似，可以选择使用更昂贵的模型

##### 主动学习+自学习

1. 对带标注的模型进行训练得到一个模型
2. 利用模型预测未标注的数据
3. 将置信度高的作为伪标记数据，将置信度低的交给人工标注
4. 将伪标记数据和人工标记数据加入带标注的数据再次训练，反复迭代

##### 控制数据的质量

- 人工标记也会犯错（和人工的学历以及任务复杂度有关）
- 最简单的做法（成本最大），将同一个样本发给多个人工，进行多数投票
  - 改进：人工和模型预测结合，将人工结果和模型预测比对，如果不吻合再继续换人

##### 弱监督学习

- 半自动化地产生标注
  - 比人工质量稍差，但是对于训练模型足够

- **数据编程**：半启发式产生标注
  - 关键词检索，规律匹配，第三方模型

##### 小结

- 产生标注的方法：	
  - 自学习：迭代模型
  - 众包：人工标注
  - 数据编程：启发式标注

- 或者也可考虑无监督学习或自监督学习